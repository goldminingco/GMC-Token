name: ðŸš€ Gas Optimization & Compute Unit Monitoring

on:
  push:
    branches: [ main, develop, feature/gas-optimization ]
    paths:
      - 'programs/gmc_token_native/src/**'
      - 'programs/gmc_token_native/Cargo.toml'
      - '.github/workflows/gas-optimization.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'programs/gmc_token_native/src/**'
      - 'programs/gmc_token_native/Cargo.toml'

env:
  SOLANA_VERSION: 1.17.22
  RUST_TOOLCHAIN: stable

jobs:
  compute-unit-analysis:
    name: ðŸ“Š Compute Unit Analysis
    runs-on: ubuntu-latest
    
    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4
        
      - name: ðŸ¦€ Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: ${{ env.RUST_TOOLCHAIN }}
          components: clippy, rustfmt
          
      - name: âš¡ Setup Solana
        uses: solana-labs/setup-solana@v1
        with:
          solana-version: ${{ env.SOLANA_VERSION }}
          
      - name: ðŸ“¦ Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
            programs/gmc_token_native/target
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-
            
      - name: ðŸ”§ Build optimized contract
        run: |
          echo "ðŸ—ï¸ Building contract with optimization flags..."
          ./build_stable.sh
          
      - name: ðŸ“ Measure compute units
        run: |
          echo "ðŸ“Š Measuring compute units for all critical instructions..."
          ./scripts/measure_compute_units.sh
          
      - name: ðŸ“ˆ Analyze performance regression
        run: |
          echo "ðŸ” Checking for performance regressions..."
          
          # Criar script de anÃ¡lise inline se nÃ£o existir
          cat > analyze_regression.py << 'EOF'
          import json
          import sys
          import os
          
          # Thresholds de compute units (baseados na estratÃ©gia)
          THRESHOLDS = {
              "process_stake": 8000,
              "process_claim_rewards": 6000, 
              "process_burn_for_boost": 4000,
              "process_transfer_with_fee": 3000,
              "calculate_dynamic_apy": 2000,
              "process_unstake": 5000,
              "update_affiliate_network": 5000,
              "register_affiliate": 3000,
              "process_vesting_claim": 4000
          }
          
          # Encontrar arquivo de mÃ©tricas mais recente
          import glob
          metric_files = glob.glob("compute_metrics_*.json")
          if not metric_files:
              print("âŒ Nenhum arquivo de mÃ©tricas encontrado")
              sys.exit(1)
              
          latest_file = max(metric_files)
          print(f"ðŸ“„ Analisando: {latest_file}")
          
          with open(latest_file, 'r') as f:
              data = json.load(f)
              
          measurements = data.get('measurements', {})
          total_regressions = 0
          total_instructions = len(measurements)
          
          print("\nðŸ“Š ANÃLISE DE PERFORMANCE:")
          print("=" * 50)
          
          for instruction, metrics in measurements.items():
              average_cu = metrics.get('average', 0)
              threshold = THRESHOLDS.get(instruction, 5000)
              
              status = "âœ… OK" if average_cu <= threshold else "âŒ REGRESSION"
              if average_cu > threshold:
                  total_regressions += 1
                  
              print(f"{status} {instruction}: {average_cu} CUs (limite: {threshold})")
              
          print(f"\nðŸ“ˆ RESUMO:")
          print(f"   Total de instruÃ§Ãµes: {total_instructions}")
          print(f"   RegressÃµes detectadas: {total_regressions}")
          print(f"   Build size: {data.get('build_size', 'N/A')}")
          
          if total_regressions > 0:
              print(f"\nâŒ FALHA: {total_regressions} instruÃ§Ãµes acima do threshold!")
              print("ðŸŽ¯ AÃ§Ãµes recomendadas:")
              print("   1. Revisar mudanÃ§as recentes no cÃ³digo")
              print("   2. Aplicar otimizaÃ§Ãµes da estratÃ©gia de gas")
              print("   3. Considerar refatoraÃ§Ã£o das funÃ§Ãµes problemÃ¡ticas")
              sys.exit(1)
          else:
              print("\nâœ… SUCESSO: Todas as instruÃ§Ãµes dentro dos limites!")
              
          EOF
          
          python analyze_regression.py
          
      - name: ðŸ“Š Generate performance report
        if: always()
        run: |
          echo "ðŸ“‹ Gerando relatÃ³rio de performance..."
          
          # Criar relatÃ³rio markdown
          cat > performance_report.md << 'EOF'
          # ðŸ“Š Performance Report - GMC Token
          
          **Data:** $(date)
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}
          
          ## ðŸ“ˆ MÃ©tricas de Compute Units
          
          EOF
          
          # Adicionar mÃ©tricas do JSON ao relatÃ³rio
          if [ -f compute_metrics_*.json ]; then
              echo "MÃ©tricas detalhadas disponÃ­veis no artifact." >> performance_report.md
          fi
          
      - name: ðŸ“¤ Upload metrics artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: compute-metrics-${{ github.sha }}
          path: |
            compute_metrics_*.json
            performance_report.md
          retention-days: 30
          
      - name: ðŸ’¬ Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            // Ler mÃ©tricas se disponÃ­vel
            let reportContent = "# ðŸ“Š AnÃ¡lise de Performance\n\n";
            
            try {
              // Procurar arquivo de mÃ©tricas
              const files = fs.readdirSync('.');
              const metricFile = files.find(f => f.startsWith('compute_metrics_'));
              
              if (metricFile) {
                const data = JSON.parse(fs.readFileSync(metricFile, 'utf8'));
                
                reportContent += `**Build Size:** ${data.build_size}\n`;
                reportContent += `**Total InstruÃ§Ãµes:** ${Object.keys(data.measurements).length}\n\n`;
                
                reportContent += "## ðŸŽ¯ Principais MÃ©tricas\n\n";
                reportContent += "| InstruÃ§Ã£o | CUs MÃ©dios | Status |\n";
                reportContent += "|-----------|------------|--------|\n";
                
                const thresholds = {
                  "process_stake": 8000,
                  "process_claim_rewards": 6000,
                  "process_burn_for_boost": 4000,
                  "process_transfer_with_fee": 3000,
                  "calculate_dynamic_apy": 2000
                };
                
                for (const [instruction, metrics] of Object.entries(data.measurements)) {
                  const avg = metrics.average;
                  const threshold = thresholds[instruction] || 5000;
                  const status = avg <= threshold ? "âœ…" : "âŒ";
                  
                  reportContent += `| ${instruction} | ${avg} | ${status} |\n`;
                }
                
                reportContent += "\n---\n";
                reportContent += "*AnÃ¡lise automÃ¡tica de compute units*";
              }
            } catch (error) {
              reportContent += "âŒ Erro ao processar mÃ©tricas de performance.";
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: reportContent
            });

  security-check:
    name: ðŸ›¡ï¸ Security & Optimization Validation
    runs-on: ubuntu-latest
    needs: compute-unit-analysis
    
    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4
        
      - name: ðŸ¦€ Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: stable
          components: clippy
          
      - name: ðŸ” Security lint with Clippy
        run: |
          cd programs/gmc_token_native
          cargo clippy --all-targets --all-features -- \
            -D warnings \
            -D clippy::integer_overflow \
            -D clippy::panic \
            -D clippy::unwrap_used \
            -W clippy::cast_possible_truncation \
            -W clippy::cast_precision_loss
            
      - name: ðŸ§ª Run security-focused tests
        run: |
          cd programs/gmc_token_native
          cargo test --release critical_tests:: -- --nocapture
          cargo test --release security:: -- --nocapture
          
      - name: ðŸ“‹ Check optimization flags
        run: |
          echo "ðŸ” Verificando flags de otimizaÃ§Ã£o..."
          
          # Verificar Cargo.toml para flags de otimizaÃ§Ã£o
          if grep -q "lto.*true" programs/gmc_token_native/Cargo.toml; then
            echo "âœ… LTO habilitado"
          else
            echo "âš ï¸ LTO nÃ£o encontrado - recomendado para otimizaÃ§Ã£o"
          fi
          
          if grep -q "codegen-units.*1" programs/gmc_token_native/Cargo.toml; then
            echo "âœ… Codegen units otimizado"
          else
            echo "â„¹ï¸ Codegen units: usando padrÃ£o"
          fi

  build-optimization-report:
    name: ðŸ“ˆ Build Optimization Report
    runs-on: ubuntu-latest
    needs: [compute-unit-analysis, security-check]
    if: always()
    
    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4
        
      - name: ðŸ“Š Download metrics
        uses: actions/download-artifact@v3
        with:
          name: compute-metrics-${{ github.sha }}
          
      - name: ðŸ“‹ Generate optimization recommendations
        run: |
          echo "# ðŸš€ RelatÃ³rio de OtimizaÃ§Ã£o GMC Token" > optimization_report.md
          echo "" >> optimization_report.md
          echo "**Gerado em:** $(date)" >> optimization_report.md
          echo "**Commit:** ${{ github.sha }}" >> optimization_report.md
          echo "" >> optimization_report.md
          
          echo "## ðŸ“Š Status Atual" >> optimization_report.md
          echo "" >> optimization_report.md
          
          if [ -f compute_metrics_*.json ]; then
            echo "âœ… MÃ©tricas de compute units coletadas" >> optimization_report.md
          else
            echo "âŒ MÃ©tricas nÃ£o disponÃ­veis" >> optimization_report.md
          fi
          
          echo "" >> optimization_report.md
          echo "## ðŸŽ¯ PrÃ³ximos Passos" >> optimization_report.md
          echo "" >> optimization_report.md
          echo "1. **AnÃ¡lise de Hotspots:** Identificar instruÃ§Ãµes com maior consumo" >> optimization_report.md
          echo "2. **Packed Structures:** Implementar data structures otimizadas" >> optimization_report.md
          echo "3. **Cache Strategy:** Implementar cache para cÃ¡lculos frequentes" >> optimization_report.md
          echo "4. **Batch Operations:** Otimizar CPIs com operaÃ§Ãµes em lote" >> optimization_report.md
          echo "" >> optimization_report.md
          echo "## ðŸ“š ReferÃªncias" >> optimization_report.md
          echo "- [EstratÃ©gia de OtimizaÃ§Ã£o](GAS_OPTIMIZATION_STRATEGY.md)" >> optimization_report.md
          echo "- [DocumentaÃ§Ã£o Solana Performance](https://docs.solana.com/developing/programming-model/performance)" >> optimization_report.md
          
      - name: ðŸ“¤ Upload final report
        uses: actions/upload-artifact@v3
        with:
          name: optimization-report-${{ github.sha }}
          path: optimization_report.md
          retention-days: 90 